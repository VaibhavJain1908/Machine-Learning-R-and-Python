#Visualising the Training set results
install.packages("ElemStatLearn",repos="http://cran.us.r-project.org")
install.packages("Rtools")
source("http://bioconductor.org/biocLite.R")
biocLite("BiocUpgrade")
source("http://bioconductor.org/biocLite.R")
biocLite("BiocUpgrade")
source("https://bioconductor.org/install")
biocLite("BiocUpgrade")
library(remotes)
install.packages("remotes")
library(remotes)
install_github("packageauthor/foobarbaz")
install_github("packageauthor/ElemStatLearn")
install_bitbucket("packageauthor/ElemStatLearn")
install_gitorious("packageauthor/ElemStatLearn")
options(install.packages.check.source = "no")
#Visualising the Training set results
install.packages("ElemStatLearn",repos="http://cran.us.r-project.org")
#Visualising the Training set results
install.packages("ElemStatLearn")
#Visualising the Training set results
install.packages("ElemStatLearn", repos = "http://r.findata.org")
#Visualising the Training set results
install.packages("ElemStatLearn", repos = "http://r.findata.org")
#Visualising the Training set results
install.packages("ElemStatLearn", repo = "https://mac.R-project.org")
wget https://cran.r-project.org/src/contrib/Archive/ElemStatLearn/
wget https://cran.r-project.org/src/contrib/Archive/ElemStatLearn
wgethttps://cran.r-project.org/src/contrib/Archive/ElemStatLearn/
wgethttps:/cran.r-project.org/src/contrib/Archive/ElemStatLearn
wget https://cran.r-project.org/src/contrib/Archive/ElemStatLearn/
wgethttps://www.rdocumentation.org/packages/ElemStatLearn
wgethttps://www.rdocumentation.org/packages/ElemStatLearn
wget https://www.rdocumentation.org/packages/ElemStatLearn
#Visualising the Training set results
install.packages("ElemStatLearn", repo = "https://mac.R-project.org")
#Visualising the Training set results
install.packages("ElemStatLearn")
#Visualising the Training set results
install.packages("ElemStatLearn")
wget https://www.rdocumentation.org/packages/ElemStatLearn
install.packages("zoomgrid")
#Visualising the Training set results
install.packages("ElemStatLearn", repos = 	"http://www-stat.stanford.edu/~tibs/ElemStatLearn/")
library(ElemStatLearn)
#Visualising the Training set results
install.packages("ElemStatLearn", repos = 	"http://www-stat.stanford.edu/~tibs/ElemStatLearn/")
#Visualising the Training set results
install.packages("ElemStatLearn")
install.packages(c("glue", "Rcpp", "rlang", "scales", "stringi"))
View(m)
install.packages("ElemStatLearn")
#Visualising the Training set results
install.packages("ElemStatLearn")
library(remotes)
install_github("cran/ElemStatLearn")
#Visualising the Training set results
install.packages("ElemStatLearn")
library(ElemStatLearn)
#How to take input
a <- readline(prompt = "Enter:")
typeof(a)
#Type Converter
a<-as.integer(a)
#Check type
typeof(a)
setwd("D:/[Tutsgalaxy.com] - Machine Learning A-Z™ Hands-On Python & R In Data Science/Machine Learning A-Z Template Folder/Part 4 - Clustering/Section 25 - Hierarchical Clustering/Hierarchical_Clustering")
#Importing the Dataset
dataset <- read.csv("Mall_Customers.csv")
View(dataset)
X <- dataset[4:5]
# Using the dendrogram to find the optimal number of clusters
dendrogram = hclust(dist(X, method = "euclidean"), method = "ward.D")
plot(dendrogram,
main = paste("Dendrogram"),
xlab = "Customers",
ylab = "Euclidean distances")
# Fitting Hierarchical clustering to the dataset
hc = hclust(dist(X, method = "euclidean"), method = "ward.D")
y_hc = cutree(hc, 5)
y_hc
K-Means Clustering
# Importing the dataset
dataset = read.csv('Mall_Customers.csv')
dataset = dataset[4:5]
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
# library(caTools)
# set.seed(123)
# split = sample.split(dataset$DependentVariable, SplitRatio = 0.8)
# training_set = subset(dataset, split == TRUE)
# test_set = subset(dataset, split == FALSE)
# Feature Scaling
# training_set = scale(training_set)
# test_set = scale(test_set)
# Using the elbow method to find the optimal number of clusters
set.seed(6)
wcss = vector()
for (i in 1:10) wcss[i] = sum(kmeans(dataset, i)$withinss)
plot(1:10,
wcss,
type = 'b',
main = paste('The Elbow Method'),
xlab = 'Number of clusters',
ylab = 'WCSS')
# Fitting K-Means to the dataset
set.seed(29)
kmeans = kmeans(x = dataset, centers = 5)
y_kmeans = kmeans$cluster
# Visualising the clusters
library(cluster)
clusplot(dataset,
y_kmeans,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 2,
plotchar = FALSE,
span = TRUE,
main = paste('Clusters of customers'),
xlab = 'Annual Income',
ylab = 'Spending Score')
#K-Means Clustering
#Importing the Dataset
dataset <- read.csv("Mall_Customers.csv")
X <- dataset[4:5]
#Using the elbow method to find the optimal number of clusters
set.seed(6)
wcss <- vector()
for (i in 1:10) wcss[i] <- sum(kmeans(X, i)$withinss)
plot(1:10, wcss, type = "b", main = paste("Cluster of Clients"), xlab = "Number of Clusters", ylab = "WcSS")
#Applying k-means to the mall dataset
set.seed(29)
kmeans <- kmeans(X, 5, iter.max = 300, nstart = 10)
#Visualising the Clusters
library(cluster)
clusplot(X,
kmeans$cluster,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 2,
plotchar = FALSE,
span = TRUE,
main = paste("Cluster of Clients"),
xlab = "Annual Income",
ylab = "Spending Score")
#Visualising the clusters
library(cluster)
clusplot(X,
y_hc,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 2,
plotchar = FALSE,
span = TRUE,
main = paste("Cluster of Clients"),
xlab = "Annual Income",
ylab = "Spending Score")
clusplot(dataset,
y_hc,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 2,
plotchar = FALSE,
span = TRUE,
main = paste('Clusters of customers'),
xlab = 'Annual Income',
ylab = 'Spending Score')
clusplot(X,
y_hc,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 2,
plotchar = FALSE,
span = TRUE,
main = paste('Clusters of customers'),
xlab = 'Annual Income',
ylab = 'Spending Score')
setwd("D:/[Tutsgalaxy.com] - Machine Learning A-Z™ Hands-On Python & R In Data Science/Machine Learning A-Z Template Folder/Part 5 - Association Rule Learning/Section 28 - Apriori/Apriori_R")
#Data Preprocessing
dataset = read.csv("Market_Basket_Optimisation.csv")
View(dataset)
#Data Preprocessing
dataset = read.csv("Market_Basket_Optimisation.csv")
#Data Preprocessing
dataset = read.csv("Market_Basket_Optimisation.csv", header = FALSE)
#Data Preprocessing
library(arules)
#Data Preprocessing
install.packages("arules")
#Data Preprocessing
#install.packages("arules")
library(arules)
dataset = read.transactions("Market_Basket_Optimisation.csv", sep = ",", rm.duplicates = TRUE)
summary(dataset)
itemFrequencyPlot(dataset, topN = 100)
itemFrequencyPlot(dataset, topN = 10)
3*7/7500
#Training Apriori on the dataset
rules = apriori(data = dataset, parameter = list(support = 0.003,confidence = 0.8))
#Training Apriori on the dataset
rules = apriori(data = dataset, parameter = list(support = 0.003,confidence = 0.4))
View(rules)
#Visualising the results
inspect(sort(rules, by = "lift")[1:10])
#Training Apriori on the dataset
rules = apriori(data = dataset, parameter = list(support = 0.003,confidence = 0.2))
#Visualising the results
inspect(sort(rules, by = "lift")[1:10])
4*7/7500
#Training Apriori on the dataset
rules = apriori(data = dataset, parameter = list(support = 0.004,confidence = 0.2))
#Visualising the results
inspect(sort(rules, by = "lift")[1:10])
